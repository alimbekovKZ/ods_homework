{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия №3\n",
    "<center>Автор материала: программист-исследователь Mail.Ru Group Юрий Кашницкий"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашнее задание № 8\n",
    "## <center> Vowpal Wabbit в задаче классификации тегов вопросов на Stackoverflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Введение\n",
    "\n",
    "В этом задании вы будете делать примерно то же, что я каждую неделю –  в Mail.Ru Group: обучать модели на выборке в несколько гигабайт. Задание можно выполнить и на Windows с Python, но я рекомендую поработать под \\*NIX-системой (например, через Docker) и активно использовать язык bash.\n",
    "Немного снобизма (простите, но правда): если вы захотите работать в лучших компаниях мира в области ML, вам все равно понадобится опыт работы с bash под UNIX.\n",
    "\n",
    "[Веб-форма](https://docs.google.com/forms/d/1VaxYXnmbpeP185qPk2_V_BzbeduVUVyTdLPQwSCxDGA/edit) для ответов.\n",
    "\n",
    "Для выполнения задания понадобится установленный Vowpal Wabbit (уже есть в докер-контейнере курса, см. инструкцию в Wiki [репозитория](https://github.com/Yorko/mlcourse_open) нашего курса) и примерно 70 Гб дискового пространства. Я тестировал решение не на каком-то суперкомпе, а на Macbook Pro 2015 (8 ядер, 16 Гб памяти), и самая тяжеловесная модель обучалась около 12 минут, так что задание реально выполнить и с простым железом. Но если вы планируете когда-либо арендовать сервера Amazon, можно попробовать это сделать уже сейчас.\n",
    "\n",
    "Материалы в помощь:\n",
    " - интерактивный [тьюториал](https://www.codecademy.com/en/courses/learn-the-command-line/lessons/environment/exercises/bash-profile) CodeAcademy по утилитам командной строки UNIX (примерно на час-полтора)\n",
    " - [статья](https://habrahabr.ru/post/280562/) про то, как арендовать на Amazon машину (еще раз: это не обязательно для выполнения задания, но будет хорошим опытом, если вы это делаете впервые)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Описание данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеются 10 Гб вопросов со StackOverflow – [скачайте](https://drive.google.com/file/d/1ZU4J3KhJDrHVMj48fROFcTsTZKorPGlG/view) и распакуйте архив. \n",
    "\n",
    "Формат данных простой:<br>\n",
    "<center>*текст вопроса* (слова через пробел) TAB *теги вопроса* (через пробел)\n",
    "\n",
    "Здесь TAB – это символ табуляции.\n",
    "Пример первой записи в выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " is there a way to apply a background color through css at the tr level i can apply it at the td level like this my td background color e8e8e8 background e8e8e8 however the background color doesn t seem to get applied when i attempt to apply the background color at the tr level like this my tr background color e8e8e8 background e8e8e8 is there a css trick to making this work or does css not natively support this for some reason \tcss css3 css-selectors\n"
     ]
    }
   ],
   "source": [
    "!\"C:\\Program Files (x86)\\GnuWin32\\bin\\head.exe\" -1 stackoverflow.10kk.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь у нас текст вопроса, затем табуляция и теги вопроса: *css, css3* и *css-selectors*. Всего в выборке таких вопросов 10 миллионов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000000 stackoverflow.10kk.tsv\n",
      "Wall time: 3min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!\"C:\\Program Files (x86)\\GnuWin32\\bin\\wc.exe\" -l stackoverflow.10kk.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание на то, что такие данные я уже не хочу загружать в оперативную память и, пока можно, буду пользоваться эффективными утилитами UNIX –  head, tail, wc, cat, cut и прочими."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте выберем в наших данных все вопросы с тегами *javascript, java, python, ruby, php, c++, c#, go, scala* и  *swift* и подготовим обучающую выборку в формате Vowpal Wabbit. Будем решать задачу 10-классовой классификации вопросов по перечисленным тегам.\n",
    "\n",
    "Вообще, как мы видим, у каждого вопроса может быть несколько тегов, но мы упростим себе задачу и будем у каждого вопроса выбирать один из перечисленных тегов либо игнорировать вопрос, если таковых тегов нет. \n",
    "Но вообще VW поддерживает multilabel classification (аргумент  --multilabel_oaa).\n",
    "<br>\n",
    "<br>\n",
    "Реализуйте в виде отдельного файла `preprocess.py` код для подготовки данных. Он должен отобрать строки, в которых есть перечисленные теги, и переписать их в отдельный файл в формат Vowpal Wabbit. Детали:\n",
    " - скрипт должен работать с аргументами командной строки: с путями к файлам на входе и на выходе\n",
    " - строки обрабатываются по одной (можно использовать tqdm для подсчета числа итераций)\n",
    " - если табуляций в строке нет или их больше одной, считаем строку поврежденной и пропускаем\n",
    " - в противном случае смотрим, сколько в строке тегов из списка *javascript, java, python, ruby, php, c++, c#, go, scala* и  *swift*. Если ровно один, то записываем строку в выходной файл в формате VW: `label | text`, где `label` – число от 1 до 10 (1 - *javascript*, ... 10 – *swift*). Пропускаем те строки, где интересующих тегов больше или меньше одного \n",
    " - из текста вопроса надо выкинуть двоеточия и вертикальные палки, если они есть – в VW это спецсимволы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from time import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Должно получиться вот такое число строк – 4389054. 10 Гб у меня обработались примерно за 2 минуты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in: stackoverflow.10kk.tsv out: stackoverflow.vw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 10000000/10000000 [21:53<00:00, 7611.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5610942 lines was corrupted\n",
      "4389058 lines was fine\n"
     ]
    }
   ],
   "source": [
    "#!python preprocess.py stackoverflow.10kk.tsv stackoverflow.vw\n",
    "%run  preprocess.py stackoverflow.10kk.tsv stackoverflow.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4389058 stackoverflow.vw\n",
      "Wall time: 4min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!\"C:\\Program Files (x86)\\GnuWin32\\bin\\wc.exe\" -l stackoverflow.vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!\"C:\\Program Files (x86)\\GnuWin32\\bin\\gzip.exe\" stackoverflow.10kk.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поделите выборку на обучающую, проверочную и тестовую части в равной пропорции - по  1463018 в каждый файл. Перемешивать не надо, первые 1463018 строк должны пойти в обучающую часть `stackoverflow_train.vw`, последние 1463018 – в тестовую `stackoverflow_test.vw`, оставшиеся – в проверочную `stackoverflow_valid.vw`. \n",
    "\n",
    "Также сохраните векторы ответов для проверочной и тестовой выборки в отдельные файлы `stackoverflow_valid_labels.txt` и `stackoverflow_test_labels.txt`.\n",
    "\n",
    "Тут вам помогут утилиты `head`, `tail`, `split`, `cat` и `cut`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 33.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!\"C:\\Program Files (x86)\\GnuWin32\\bin\\head.exe\" -n 1463018 stackoverflow.vw > stackoverflow_train.vw\n",
    "!\"C:\\Program Files (x86)\\GnuWin32\\bin\\head.exe\" -n 2926036 stackoverflow.vw | \"C:\\Program Files (x86)\\GnuWin32\\bin\\tail.exe\"  -n 1463018 > stackoverflow_valid.vw\n",
    "!\"C:\\Program Files (x86)\\GnuWin32\\bin\\tail.exe\" -n 1463018 stackoverflow.vw > stackoverflow_test.vw\n",
    "\n",
    "!\"C:\\Program Files (x86)\\GnuWin32\\bin\\cat.exe\" stackoverflow_test.vw | \"C:\\Program Files (x86)\\GnuWin32\\bin\\cut.exe\" -f1 -d \"|\" > stackoverflow_test_labels.txt\n",
    "!\"C:\\Program Files (x86)\\GnuWin32\\bin\\cat.exe\" stackoverflow_valid.vw | \"C:\\Program Files (x86)\\GnuWin32\\bin\\cut.exe\" -f1 -d \"|\" > stackoverflow_valid_labels.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1463018 stackoverflow_train.vw\n",
      "1463018 stackoverflow_valid.vw\n",
      "1463018 stackoverflow_test.vw\n",
      "1463018 stackoverflow_valid_labels.txt\n",
      "1463018 stackoverflow_test_labels.txt\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!\"C:\\Program Files (x86)\\GnuWin32\\bin\\wc.exe\" -l stackoverflow_train.vw\n",
    "!\"C:\\Program Files (x86)\\GnuWin32\\bin\\wc.exe\" -l stackoverflow_valid.vw\n",
    "!\"C:\\Program Files (x86)\\GnuWin32\\bin\\wc.exe\" -l stackoverflow_test.vw\n",
    "!\"C:\\Program Files (x86)\\GnuWin32\\bin\\wc.exe\" -l stackoverflow_valid_labels.txt\n",
    "!\"C:\\Program Files (x86)\\GnuWin32\\bin\\wc.exe\" -l stackoverflow_test_labels.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Обучение и проверка моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите Vowpal Wabbit на выборке `stackoverflow_train.vw` 9 раз, перебирая параметры passes (1,3,5), ngram (1,2,3).\n",
    "Остальные параметры укажите следующие: `loss_function=hinge`, `bit_precision`=28 и `seed`=17. Также скажите VW, что это 10-классовая задача.\n",
    "\n",
    "Проверяйте долю правильных ответов на выборке `stackoverflow_valid.vw`. Выберите лучшую модель и проверьте качество на выборке `stackoverflow_test.vw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "666c9bd10a174fc386e8b216221ed139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn: passes=1; ngram=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating 1-grams for all namespaces.\n",
      "final_regressor = valid_model.vw\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "creating cache_file = stackoverflow_train.vw.cache\n",
      "Reading datafile = stackoverflow_train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1      129\n",
      "0.500000 1.000000            2            2.0        4        1       53\n",
      "0.750000 1.000000            4            4.0        7        1       55\n",
      "0.750000 0.750000            8            8.0        7        1       76\n",
      "0.750000 0.750000           16           16.0        7        7      153\n",
      "0.812500 0.875000           32           32.0        7        2      150\n",
      "0.765625 0.718750           64           64.0        3        3      188\n",
      "0.664063 0.562500          128          128.0        1        5       21\n",
      "0.578125 0.492188          256          256.0        5        1      129\n",
      "0.525391 0.472656          512          512.0        2        2      238\n",
      "0.439453 0.353516         1024         1024.0        3        3       96\n",
      "0.368652 0.297852         2048         2048.0        1        1       58\n",
      "0.304688 0.240723         4096         4096.0        1        1       64\n",
      "0.257324 0.209961         8192         8192.0        2        2       89\n",
      "0.216736 0.176147        16384        16384.0        7        7      172\n",
      "0.183716 0.150696        32768        32768.0        4        5      109\n",
      "0.161255 0.138794        65536        65536.0        5        5      107\n",
      "0.142632 0.124008       131072       131072.0        7        2      206\n",
      "0.125832 0.109032       262144       262144.0        7        7       68\n",
      "0.113800 0.101768       524288       524288.0        1        1      535\n",
      "0.104834 0.095867      1048576      1048576.0        1        1      430\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1463018\n",
      "passes used = 1\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.100788\n",
      "total feature number = 210616841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test on valid...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating 1-grams for all namespaces.\n",
      "only testing\n",
      "predictions = valid_predictions.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = stackoverflow_valid.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        2        2      138\n",
      "0.000000 0.000000            2            2.0        7        7       61\n",
      "0.000000 0.000000            4            4.0        5        5      202\n",
      "0.000000 0.000000            8            8.0        7        7      106\n",
      "0.000000 0.000000           16           16.0        6        6      229\n",
      "0.000000 0.000000           32           32.0        2        2      327\n",
      "0.062500 0.125000           64           64.0        5        5      667\n",
      "0.054688 0.046875          128          128.0        2        2      103\n",
      "0.097656 0.140625          256          256.0        6        6       62\n",
      "0.085938 0.074219          512          512.0        7        1       21\n",
      "0.079102 0.072266         1024         1024.0        1        1       55\n",
      "0.086914 0.094727         2048         2048.0        2        2      195\n",
      "0.085449 0.083984         4096         4096.0        2        2      233\n",
      "0.089111 0.092773         8192         8192.0        7        7      218\n",
      "0.089233 0.089355        16384        16384.0        2        2      101\n",
      "0.088440 0.087646        32768        32768.0        1        1       85\n",
      "0.090363 0.092285        65536        65536.0        2        2       60\n",
      "0.089882 0.089401       131072       131072.0        2        2       12\n",
      "0.089729 0.089577       262144       262144.0        6        6       66\n",
      "0.089909 0.090088       524288       524288.0        5        5      236\n",
      "0.090174 0.090439      1048576      1048576.0        4        2       48\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 1463018\n",
      "passes used = 1\n",
      "weighted example sum = 1463018.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.089987\n",
      "total feature number = 210603807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.9100127271161393\n",
      "learn: passes=1; ngram=2\n"
     ]
    }
   ],
   "source": [
    "passes = [1, 3, 5]\n",
    "ngram = [1, 2, 3]\n",
    "\n",
    "params = [(p, n) for p in passes for n in ngram]\n",
    "\n",
    "with open('stackoverflow_valid_labels.txt', 'r') as file:\n",
    "    valid_labels = [int(label.strip()) for label in file]\n",
    "\n",
    "best_score = 0\n",
    "best_params = None\n",
    "\n",
    "for (p, n) in tqdm_notebook(params):\n",
    "    print('learn: passes={}; ngram={}'.format(p, n))\n",
    "    !\"C:\\Program Files\\VowpalWabbit\\vw.exe\" --oaa 10 -d stackoverflow_train.vw --loss_function=hinge --bit_precision 28 --random_seed 17 \\\n",
    "        -f valid_model.vw --cache --passes $p --ngram $n \n",
    "    print('test on valid...')\n",
    "    !\"C:\\Program Files\\VowpalWabbit\\vw.exe\" -i valid_model.vw -t -d stackoverflow_valid.vw \\\n",
    "        -p valid_predictions.txt\n",
    "    with open('valid_predictions.txt', 'r') as file:\n",
    "        test_labels = [int(label.strip()) for label in file]\n",
    "    acc = accuracy_score(valid_labels, test_labels)\n",
    "    print('accuracy={}'.format(acc))\n",
    "    if acc > best_score:\n",
    "        best_params = (p, n)\n",
    "        best_score = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_vw_model(train_vw_file, model_filename, num_classes=10,\n",
    "                   ngram=1, loss_function='hinge',\n",
    "                   bit_precision=28, passes=1,\n",
    "                   seed=17, quiet=True):\n",
    "    init_time = time()\n",
    "    vw_call_string = ('\"C:/Program Files/VowpalWabbit/vw.exe\" --oaa {num_classes} {train_vw_file} ' + \n",
    "                      '-f {model_filename} -b {bit_precision} ' +\n",
    "                      '--loss_function {loss_function} --random_seed {seed}').format(\n",
    "                       num_classes=num_classes, train_vw_file=train_vw_file, \n",
    "                        loss_function=loss_function,\n",
    "                       model_filename=model_filename, \n",
    "        bit_precision=bit_precision, seed=seed)\n",
    "    if ngram > 1:\n",
    "         vw_call_string += ' --ngram={}'.format(ngram)\n",
    "            \n",
    "    if passes > 1:\n",
    "         vw_call_string += ' -k --passes={} --cache_file {}'.format(passes, \n",
    "                            model_filename.replace('.vw', '.cache'))\n",
    "    if quiet:\n",
    "        vw_call_string += ' --quiet'\n",
    "    \n",
    "    \n",
    "    print(vw_call_string) \n",
    "    res = os.system(vw_call_string)\n",
    "    print('Success. Elapsed: {} sec.'.format(round(time() - init_time, 2))\n",
    "          if not res else 'Failed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_vw_model(model_filename, test_vw_file, prediction_filename,\n",
    "                  true_labels, seed=17, quiet=True):\n",
    "    init_time = time()\n",
    "    vw_call_string = ('\"C:/Program Files/VowpalWabbit/vw.exe\" -t -i {model_filename} {test_vw_file} ' + \n",
    "                       '-p {prediction_filename} --random_seed {seed}').format(\n",
    "                       model_filename=model_filename, test_vw_file=test_vw_file, \n",
    "                       prediction_filename=prediction_filename, seed=seed)\n",
    "    if quiet:\n",
    "        vw_call_string += ' --quiet'\n",
    "        \n",
    "    print(vw_call_string) \n",
    "    res = os.system(vw_call_string)\n",
    "    \n",
    "    if not res: # the call resulted OK\n",
    "        vw_pred = np.loadtxt(prediction_filename)\n",
    "        print(\"Accuracy: {}%. Elapsed: {} sec.\".format(\n",
    "            round(100 * accuracy_score(true_labels, vw_pred), 2), \n",
    "            round(time() - init_time, 2)))\n",
    "    else:\n",
    "        print('Failed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_valid = np.loadtxt('stackoverflow_valid_labels.txt')\n",
    "y_test = np.loadtxt('stackoverflow_test_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"C:/Program Files/VowpalWabbit/vw.exe\" --oaa 10 stackoverflow_train.vw -f vw_model0_part.vw -b 28 --loss_function hinge --random_seed 17 --quiet\n",
      "Success. Elapsed: 266.07 sec.\n",
      "\"C:/Program Files/VowpalWabbit/vw.exe\" -t -i vw_model0_part.vw stackoverflow_valid.vw -p vw_valid_pred0.csv --random_seed 17 --quiet\n",
      "Accuracy: 91.0%. Elapsed: 89.51 sec.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [05:58, 358.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"C:/Program Files/VowpalWabbit/vw.exe\" --oaa 10 stackoverflow_train.vw -f vw_model1_part.vw -b 28 --loss_function hinge --random_seed 17 -k --passes=3 --cache_file vw_model1_part.cache --quiet\n"
     ]
    }
   ],
   "source": [
    "for i, (ngram, passes) in tqdm(enumerate(itertools.product([1,2,3], \n",
    "                                                      [1,3,5]))):\n",
    "    train_vw_model('stackoverflow_train.vw',\n",
    "                   'vw_model{}_part.vw'.format(i), \n",
    "                   ngram=ngram, passes=passes,\n",
    "                   loss_function='hinge',\n",
    "                   num_classes=10, bit_precision=28, \n",
    "                   seed=17, quiet=True)\n",
    "    test_vw_model(model_filename='vw_model{}_part.vw'.format(i), \n",
    "              test_vw_file='stackoverflow_valid.vw', \n",
    "              prediction_filename='vw_valid_pred{}.csv'.format(i),\n",
    "              true_labels=y_valid, seed=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> Вопрос 1.</font> Какое сочетание параметров дает наибольшую долю правильных ответов на проверочной выборке `stackoverflow_valid.vw`?\n",
    "- Биграммы и 3 прохода по выборке\n",
    "- Триграммы и 5 проходов по выборке\n",
    "- Биграммы и 1 проход по выборке\n",
    "- Униграммы и 1 проход по выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверьте лучшую (по доле правильных ответов на валидации) модель на тестовой выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> Вопрос 2.</font> Как соотносятся доли правильных ответов лучшей (по доле правильных ответов на валидации) модели на проверочной и на тестовой выборках? (здесь % – это процентный пункт, т.е., скажем, снижение с 50% до 40% – это на 10%, а не 20%).\n",
    "- На тестовой ниже примерно на 2%\n",
    "- На тестовой ниже примерно на 3%\n",
    "- Результаты почти одинаковы – отличаются меньше чем на 0.5%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите VW с параметрами, подобранными на проверочной выборке, теперь на объединении обучающей и проверочной выборок. Посчитайте долю правильных ответов на тестовой выборке. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' ВАШ КОД ЗДЕСЬ '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> Вопрос 3.</font> На сколько процентных пунктов повысилась доля правильных ответов модели после обучения на вдвое большей выборке (обучающая `stackoverflow_train.vw` + проверочная `stackoverflow_valid.vw`) по сравнению с моделью, обученной только на `stackoverflow_train.vw`?\n",
    " - 0.1%\n",
    " - 0.4%\n",
    " - 0.8%\n",
    " - 1.2%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы только познакомились с Vowpal Wabbit. Что еще можно попробовать:\n",
    " - Классификация с несколькими ответами (multilabel classification, аргумент  `multilabel_oaa`) – формат данных тут как раз под такую задачу\n",
    " - Настройка параметров VW с hyperopt, авторы библиотеки утверждают, что качество должно сильно зависеть от параметров изменения шага градиентного спуска (`initial_t` и `power_t`). Также можно потестировать разные функции потерь – обучать логистическую регресиию или линейный SVM\n",
    " - Познакомиться с факторизационными машинами и их реализацией в VW (аргумент `lrq`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
